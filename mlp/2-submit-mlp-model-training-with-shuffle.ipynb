{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad72042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as ssp\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from os.path import join as pjoin\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import importlib \n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "import pytorch_lightning as pl\n",
    "from os.path import join as pjoin\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f0ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f69ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e981d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iddf = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248053ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccc1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0d8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"submit_dataset/\"\n",
    "loads = ['tr_ds', 'val_ds', 'val_csv','tr_csv', \n",
    "         'leaderboard_ds', 'final_ds', 'leaderboard_csv', \n",
    "         'final_csv', 'id2idx', 'cv']\n",
    "rets = []\n",
    "for l in loads:\n",
    "    rets.append(joblib.load(wd + l))\n",
    "tr_02_ds, val_ds, val_csv, tr_csv_02, l_ds, f_ds, l_csv, f_csv, id2idx, cv = rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce8714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2id = {y:x for (x,y) in id2idx.items()}\n",
    "n_items = len(id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2398d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/project/rw/recsys2022/tony/submit/indices\r\n"
     ]
    }
   ],
   "source": [
    "ls /data/project/rw/recsys2022/tony/submit/indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02fbad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_idmap = joblib.load('../processed_submit/indices')[0]\n",
    "# idmap = [idmap[idx2id[x]] for x in range(len(idx2id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "01ba4773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23691"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_idmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b94b583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_last_20\n",
      "item_last_5\n",
      "item_last_2\n",
      "item_last_1\n",
      "item_last_5_feats\n",
      "item_last_3_feats\n",
      "item_last_1_feats\n",
      "item_last_20\n",
      "item_last_5\n",
      "item_last_2\n",
      "item_last_1\n",
      "item_last_5_feats\n",
      "item_last_3_feats\n",
      "item_last_1_feats\n",
      "item_last_20\n",
      "item_last_5\n",
      "item_last_2\n",
      "item_last_1\n",
      "item_last_5_feats\n",
      "item_last_3_feats\n",
      "item_last_1_feats\n"
     ]
    }
   ],
   "source": [
    "import mlps\n",
    "importlib.reload(mlps)\n",
    "\n",
    "\n",
    "lr = 1.5 * 1e-4\n",
    "\n",
    "def get_model(dim=256):\n",
    "    return mlps.MLP(tr_02_ds.matrices, \n",
    "                    tr_02_ds.categoricals,  \n",
    "                    tr_02_ds.tr_scalar,\n",
    "                    n_items=n_items, \n",
    "                    dim=np.random.choice([256]), \n",
    "                    layer_dim=np.random.choice([3000]),\n",
    "                    dropout=np.random.choice([0.3, 0.35]),\n",
    "                    use_cat=False,\n",
    "                    num_feats=904)\n",
    "\n",
    "softmax_models = [get_model() for x in range(n_models)]\n",
    "def get_opts(model):\n",
    "    wd = np.random.choice([1e-3, 3e-3])\n",
    "    return torch.optim.Adam(model.parameters(),  lr=lr, weight_decay=wd)\n",
    "\n",
    "opts = [get_opts(model) for model in softmax_models]\n",
    "for m in softmax_models:\n",
    "    m.cuda()\n",
    "    m.train()\n",
    "lf = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d584a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_models(models, val_ds, use_filter=True, skip_val_only=False):\n",
    "    hr = []\n",
    "    for model in models:\n",
    "        model = model.eval()\n",
    "    s = 0\n",
    "    tot_mrr = []\n",
    "    ii = 0\n",
    "    for input in DataLoader(val_ds, batch_size=250, shuffle=True):\n",
    "        (target_idx, _), (ret_mat, ret_cat, ret_scalar) = input\n",
    "        for k in ret_mat:\n",
    "            ret_mat[k] = ret_mat[k].cuda()\n",
    "        for k in ret_cat:\n",
    "            ret_cat[k] = ret_cat[k].cuda()\n",
    "        ret_scalar = ret_scalar.cuda()\n",
    "        rret = []\n",
    "        for model in models:\n",
    "            ret = model.forward(ret_mat, ret_cat, ret_scalar,)\n",
    "            rret.append(ret)\n",
    "        ret = torch.stack(rret)\n",
    "        ret = torch.mean(ret, 0)\n",
    "        ret[ret_mat['item_bow'].bool()] = -10000.0\n",
    "        top_rec = (-ret).argsort(-1)[:, :100].detach().cpu()\n",
    "\n",
    "#         if skip_val_only:\n",
    "#         top_rec = top_rec[target_idx != 29999]\n",
    "#         target_idx = target_idx[target_idx != 29999]\n",
    "\n",
    "        mrr = (top_rec == target_idx.unsqueeze(1)).float().numpy()\n",
    "        hitst = mrr[:, :5].sum(-1)\n",
    "        mrr = (mrr / np.expand_dims(np.arange(1, 1 + 100), 0)).sum(-1)\n",
    "        tot_mrr.extend(mrr.tolist())\n",
    "        hr.extend(hitst)\n",
    "    for model in models:\n",
    "        model = model.train()\n",
    "    return np.mean(tot_mrr), np.mean(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798703c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_884/11893372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_ds' is not defined"
     ]
    }
   ],
   "source": [
    "mrr, hr = validate_models(softmax_models, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4faf3e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:42<00:00, 10.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:28<00:00, 11.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:26<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 1] VAL MRR: 0.24331715547847216 HR 0.32433334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:45<00:00, 10.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 2] VAL MRR: 0.25901853241850287 HR 0.34766668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:40<00:00, 10.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 3] VAL MRR: 0.26606223416740493 HR 0.35533333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 4] VAL MRR: 0.26712359339184916 HR 0.36166668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:41<00:00, 10.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 5] VAL MRR: 0.27004931490934586 HR 0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:50<00:00, 10.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:52<00:00, 10.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:40<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 6] VAL MRR: 0.273069622637811 HR 0.35666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 7] VAL MRR: 0.2734842435387534 HR 0.36166668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:38<00:00, 11.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 8] VAL MRR: 0.27428981209273534 HR 0.36266667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 9] VAL MRR: 0.2767052881077822 HR 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:40<00:00, 10.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:50<00:00, 10.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 10] VAL MRR: 0.27913545710599214 HR 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:41<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 11] VAL MRR: 0.2775628158605176 HR 0.36766666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:51<00:00, 10.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 12] VAL MRR: 0.2806985404335769 HR 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:44<00:00, 10.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 13] VAL MRR: 0.2809601754609205 HR 0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 14] VAL MRR: 0.2806530080348543 HR 0.37266666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:42<00:00, 10.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:45<00:00, 10.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:45<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 15] VAL MRR: 0.2819780623126937 HR 0.37233335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:40<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 16] VAL MRR: 0.28137910776813363 HR 0.36633334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 17] VAL MRR: 0.27913318142767707 HR 0.37333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:39<00:00, 10.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 18] VAL MRR: 0.2800309431995905 HR 0.37066665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:51<00:00, 10.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 19] VAL MRR: 0.2855656757690586 HR 0.37566668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:44<00:00, 10.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:46<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 20] VAL MRR: 0.28595391948384863 HR 0.38133332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:39<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 21] VAL MRR: 0.2837392656868908 HR 0.37433332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 22] VAL MRR: 0.28661169936015185 HR 0.37633333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:40<00:00, 10.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 23] VAL MRR: 0.2854300906585133 HR 0.37566668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 24] VAL MRR: 0.28403635610806777 HR 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:40<00:00, 10.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 25] VAL MRR: 0.2823149436840812 HR 0.37433332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:50<00:00, 10.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:45<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 26] VAL MRR: 0.2859347886108372 HR 0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 27] VAL MRR: 0.2848845621607791 HR 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:43<00:00, 10.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:49<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 28] VAL MRR: 0.2864656733105506 HR 0.37633333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:47<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 29] VAL MRR: 0.2867516232939475 HR 0.38333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:41<00:00, 10.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1738/1738 [02:48<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 30] VAL MRR: 0.28806020931535575 HR 0.38233334\n"
     ]
    }
   ],
   "source": [
    "tr_dls = [DataLoader(tr_02_ds,\n",
    "                   batch_size=256, shuffle=True,\n",
    "                   num_workers=8, prefetch_factor=2,\n",
    "                   pin_memory=True) for _ in range(n_models)]\n",
    "\n",
    "loss_ = np.log(n_items)\n",
    "max_mrr = -1\n",
    "for epoch in range(30):\n",
    "    it = 0\n",
    "    iidx = 0   \n",
    "    for tr_dl, model, optimizer in zip(tr_dls, softmax_models, opts):\n",
    "        pbar = tqdm(tr_dl)\n",
    "        for x in pbar:\n",
    "            (target_idx, mask), (mats, cats, scalars) = x\n",
    "            target_idx = target_idx.cuda()\n",
    "            mask = mask.cuda().squeeze(1)\n",
    "\n",
    "            for k in mats:\n",
    "                mats[k] = mats[k].cuda()\n",
    "            for k in cats:\n",
    "                cats[k] = cats[k].cuda()\n",
    "            scalars = scalars.cuda()\n",
    "            model.zero_grad()\n",
    "            pred = model(mats, cats, scalars)\n",
    "            pred[mask.bool()] = -10000.0\n",
    "            ce_loss = lf(pred, target_idx).mean()        \n",
    "            loss = ce_loss\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "        loss_ = 0.99 * loss_  + 0.01 * loss.detach().cpu().numpy()\n",
    "        pbar.set_postfix({'loss:': \"%0.4f\" % loss_})\n",
    "\n",
    "    model = softmax_models[0]\n",
    "    model = model.eval()\n",
    "    mrr, hr = validate_models(softmax_models, val_ds)\n",
    "    \n",
    "    if mrr >= max_mrr:\n",
    "        torch.save(softmax_models, 'submit_softmax_model_shuffle')\n",
    "        max_mrr = mrr \n",
    "    print(\"[ITER %d] VAL MRR:\" % (1 + epoch), mrr, \"HR\", hr)\n",
    "    model = model.train()\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf3037",
   "metadata": {},
   "source": [
    "softmax_models = torch.load('submit_softmax_model')\n",
    "softmax_models = [m.cuda().eval() for m in softmax_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5cbdd4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_models = torch.load('submit_softmax_model_shuffle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9548fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_models = [model.cuda().eval() for model in softmax_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64aea5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr, hr = validate_models(softmax_models, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f01e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28806020931535575, 0.38233334)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fddf1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dl = DataLoader(l_ds, batch_size=250, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1dc11bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  8.79it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = []\n",
    "softmax_models = [model.cuda().eval() for model in softmax_models]\n",
    "for x in tqdm(l_dl):\n",
    "    (target_idx, mask), (mats, cats, scalars) = x\n",
    "    target_idx = target_idx.cuda()\n",
    "    mask = mask.cuda().squeeze(1)\n",
    "\n",
    "    for k in mats:\n",
    "        mats[k] = mats[k].cuda()\n",
    "    for k in cats:\n",
    "        cats[k] = cats[k].cuda()\n",
    "#         cats = {}\n",
    "    scalars = scalars.cuda()\n",
    "    preds = []\n",
    "    for model in softmax_models:\n",
    "        model.zero_grad()\n",
    "        pred = model(mats, cats, scalars)\n",
    "        preds.append(pred)\n",
    "    pred = torch.stack(preds, 0).mean(0)\n",
    "    pred[mask.bool()] = -100000.0\n",
    "    ret.append(pred.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "166fed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = np.vstack(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c890d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_idmap = joblib.load('../processed_submit/indices')[0]\n",
    "def new_logit_map(logits, idmap):\n",
    "    new_map = np.ones(shape=(logits.shape[0], np.max(list(final_idmap.values())) + 1)) * -100000.0\n",
    "    idmap = [final_idmap[idx2id[x]] for x in range(len(idx2id))]\n",
    "    new_map[:, idmap] = logits\n",
    "    return new_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59071d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_logits = new_logit_map(ret, final_idmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05b8ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dl = DataLoader(l_ds, batch_size=250, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "096acf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:23<00:00,  8.66it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = []\n",
    "softmax_models = [model.cuda().eval() for model in softmax_models]\n",
    "for x in tqdm(f_dl):\n",
    "    (target_idx, mask), (mats, cats, scalars) = x\n",
    "    target_idx = target_idx.cuda()\n",
    "    mask = mask.cuda().squeeze(1)\n",
    "\n",
    "    for k in mats:\n",
    "        mats[k] = mats[k].cuda()\n",
    "    for k in cats:\n",
    "        cats[k] = cats[k].cuda()\n",
    "#         cats = {}\n",
    "    scalars = scalars.cuda()\n",
    "    preds = []\n",
    "    for model in softmax_models:\n",
    "        model.zero_grad()\n",
    "        pred = model(mats, cats, scalars)\n",
    "        preds.append(pred)\n",
    "    pred = torch.stack(preds, 0).mean(0)\n",
    "    pred[mask.bool()] = -100000.0\n",
    "    ret.append(pred.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "032359e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = np.vstack(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "934e8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_logits = new_logit_map(ret, final_idmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "869d8b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 23691)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b355d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../logits/final/mlp-shuffle-*\n",
    "!rm -rf ../logits/leader/mlp-shuffle-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "191af7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 23691)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e82d38d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../logits/final/mlp-shuffle-1657100572']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.makedirs(\"../logits/leader\", exist_ok=True)\n",
    "os.makedirs(\"../logits/final\", exist_ok=True)\n",
    "joblib.dump(\n",
    "    (l_csv.session_id.tolist(), leaderboard_logits),\n",
    "    \"../logits/leader/mlp-shuffle-%d\" % int(time.time()))\n",
    "\n",
    "joblib.dump(\n",
    "    (f_csv.session_id.tolist(), leaderboard_logits),\n",
    "    \"../logits/final/mlp-shuffle-%d\" % int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378fbea",
   "metadata": {},
   "source": [
    "cands = pd.read_csv('../data/candidate_items.csv', dtype=str).item_id.tolist()\n",
    "cands = set(cands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b24867",
   "metadata": {},
   "source": [
    "len(cands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57899664",
   "metadata": {},
   "source": [
    "_ret = ret + ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75504b3",
   "metadata": {},
   "source": [
    "ls \"/data/project/rw/recsys2022/ensemble/mlp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547e450",
   "metadata": {},
   "source": [
    "topks = (-_ret).argsort(-1)[:, :300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b43e92",
   "metadata": {},
   "source": [
    "df = {\n",
    "    'session_id': [],\n",
    "    'item_id': [],\n",
    "    'rank': [],\n",
    "}\n",
    "for sid, topk in  zip(l_csv.session_id, topks):\n",
    "#     print(sid, recs)\n",
    "    recs = [idx2id[x] for x in topk]\n",
    "    recs = [x for x in recs if x in cands][:100]\n",
    "    if len(recs) < 100:\n",
    "        print(len(recs))\n",
    "    for rank, rec in zip(range(1, 101), recs):\n",
    "        df['session_id'].append(sid)\n",
    "        df['item_id'].append(rec)\n",
    "        df['rank'].append(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba898a",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931c3b2",
   "metadata": {},
   "source": [
    "df['session_id'] = df['session_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f12386",
   "metadata": {},
   "source": [
    "df = df.sort_values(by=['session_id', 'rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99b935",
   "metadata": {},
   "source": [
    "df.to_csv(\"df_noshuffle_shuffle_together.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af202074",
   "metadata": {},
   "source": [
    "sample = pd.read_csv(\"../sample.csv\", dtype=str).sort_values(by=['session_id', 'rank']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6b5f8",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"df_1.csv\", dtype=str).sort_values(by=['session_id', 'rank']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e48cb",
   "metadata": {},
   "source": [
    "a = set(sample['item_id'].tolist()) - cands\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c565591",
   "metadata": {},
   "source": [
    "df.to_csv(\"ret\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c59070",
   "metadata": {},
   "source": [
    "ls -al /data/project/rw/recsys2022/recsys2022.git/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349add69",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
