{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad72042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as ssp\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from os.path import join as pjoin\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import joblib\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import importlib \n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "import pytorch_lightning as pl\n",
    "from os.path import join as pjoin\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47df8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/project/rw/recsys2022/vali_2105\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5b5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(sessions, purchases=None):\n",
    "    item_feats = pd.read_csv(pjoin(data_dir,'item_features.csv'), dtype=str)\n",
    "    item_feats['feat_id'] = item_feats['feature_category_id'] + ':' + item_feats['feature_value_id']\n",
    "    d = item_feats.groupby(\"item_id\")['feat_id'].apply(list).reset_index()\n",
    "    item_to_feats = {x:y for (x, y) in zip(d.item_id, d.feat_id)}\n",
    "\n",
    "    def items_to_feats(item_ids, item_to_feats):\n",
    "        ret = []\n",
    "        for x in item_ids:\n",
    "            ret.extend(item_to_feats[x])\n",
    "        return ret\n",
    "\n",
    "    sessions['kp'] = [(x,y) for (x,y) in zip(sessions.date, sessions.item_id)]\n",
    "    t = sessions.groupby('session_id').kp.apply(lambda x: [y for y in sorted(x)]).reset_index()\n",
    "    q = sessions.groupby('session_id')['date'].apply(lambda x: list(sorted(x))[0])\n",
    "    v = sessions.groupby('session_id')['date'].apply(lambda x: list(sorted(x))[-1])\n",
    "    q = pd.merge(q, v, on='session_id')\n",
    "    print(t.shape, q.shape,v.shape)\n",
    "    ret = pd.merge(pd.DataFrame(t), pd.DataFrame(q), on='session_id')\n",
    "    if purchases is not None:\n",
    "        dataset = pd.merge(ret, purchases, on='session_id')\n",
    "        dataset.columns = ['session_id', 'item_ids', 'date_session_begin', 'date_session_end', 'target_item', 'date_purchase']\n",
    "        dataset['target_feat'] = dataset.target_item.apply(lambda x: item_to_feats[x])\n",
    "    else:\n",
    "        dataset = ret\n",
    "        dataset.columns = ['session_id', 'item_ids', 'date_session_begin', 'date_session_end']\n",
    "\n",
    "    dataset['feats'] = dataset.item_ids.apply(lambda x: items_to_feats([y[1] for y in x], item_to_feats))\n",
    "    dataset['ym'] = dataset.date_session_end.apply(lambda x:x[:7])\n",
    "    dataset['year'] = dataset.date_session_end.apply(lambda x:x[:4])\n",
    "    dataset['month'] = dataset.date_session_end.apply(lambda x:x[5:7])\n",
    "    dataset['dow'] =  pd.to_datetime(dataset.date_session_end).dt.dayofweek.apply(lambda x: str(x))\n",
    "    dataset.sort_values(by='date_session_end', inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4dd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = pd.read_csv(pjoin(data_dir, 'train_sessions.csv'), dtype=str)\n",
    "train_purchases = pd.read_csv(pjoin(data_dir, 'train_purchases.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9341d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = train_sessions[train_sessions.date >= '2021-02-01 00:00:00.000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87427f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sessions = pd.read_csv(pjoin(data_dir, 'val_sessions.csv'), dtype=str)\n",
    "val_purchases = pd.read_csv(pjoin(data_dir, 'val_purchases.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c60f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_sessions = pd.read_csv(pjoin(data_dir, 'te_sessions.csv'), dtype=str)\n",
    "te_purchases = pd.read_csv(pjoin(data_dir, 'te_purchases.csv'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b471e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178366, 2) (178366, 2) (178366,)\n"
     ]
    }
   ],
   "source": [
    "_tr_csv = build_dataset(train_sessions, train_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1411bd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40808, 2) (40808, 2) (40808,)\n"
     ]
    }
   ],
   "source": [
    "val_csv = build_dataset(val_sessions, val_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f837e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40810, 2) (40810, 2) (40810,)\n"
     ]
    }
   ],
   "source": [
    "te_csv = build_dataset(te_sessions, te_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "060f125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(y):\n",
    "    x = []\n",
    "    for k in y:\n",
    "        x.extend(k)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1b14c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = (set(flatten(_tr_csv.item_ids.apply(lambda y: [x[1] for x in y]).tolist())) | \n",
    "         set(_tr_csv.target_item.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc85c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "tptp = (val_csv.item_ids.apply(lambda y: len([x[1] for x in y if x[1] not in items])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bfade97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42160078280419716"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 / (val_csv.item_ids.apply(lambda y: len(y))[tptp >= 1] / val_csv.item_ids.apply(lambda y: len([x[1] for x in y if x[1] not in items]))[tptp >= 1])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa8ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2 = _tr_csv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbdfda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2['target_item'] = tr2['item_ids'].apply(lambda x:x[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2['item_ids'] = tr2['item_ids'].apply(lambda x:x[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ed57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2 = tr2[tr2.item_ids.apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a169b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_csv = pd.concat([tr2.reset_index(drop=True), _tr_csv.reset_index(drop=True)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e201298",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_csv = tr_csv.sort_values(by='date_session_end').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead38bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "item_feats = pd.read_csv(pjoin(data_dir, 'item_features.csv'), dtype=str)\n",
    "item_feats['feat_id'] = item_feats['feature_category_id'] + ':' + item_feats['feature_value_id']\n",
    "d = item_feats.groupby(\"item_id\")['feat_id'].apply(list).reset_index()\n",
    "item_to_feats = {x:y for (x, y) in zip(d.item_id, d.feat_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089416dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cands = set(pd.read_csv(pjoin(data_dir, \"candidate_items.csv\"), dtype=str).item_id.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2756e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_csv = _tr_csv.reset_index(drop=True)\n",
    "val_csv = val_csv.reset_index(drop=True)\n",
    "te_csv = te_csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa00f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dur = (pd.to_datetime(tr_csv.item_ids.apply(lambda x: x[-1][0])) - pd.to_datetime(tr_csv.item_ids.apply(lambda x: x[0][0]))).dt.seconds\n",
    "val_dur = (pd.to_datetime(val_csv.item_ids.apply(lambda x: x[-1][0])) - pd.to_datetime(val_csv.item_ids.apply(lambda x: x[0][0]))).dt.seconds\n",
    "te_dur = (pd.to_datetime(te_csv.item_ids.apply(lambda x: x[-1][0])) - pd.to_datetime(te_csv.item_ids.apply(lambda x: x[0][0]))).dt.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0149681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_csv['item_ids'] = tr_csv.item_ids.apply(lambda x : [y[1] for y in x])\n",
    "val_csv['item_ids'] = val_csv.item_ids.apply(lambda x : [y[1] for y in x])\n",
    "te_csv['item_ids'] = te_csv.item_ids.apply(lambda x : [y[1] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_l = tr_csv.item_ids.apply(len)\n",
    "val_l = val_csv.item_ids.apply(len)\n",
    "te_l = te_csv.item_ids.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a53b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pop_all = Counter(flatten(tr_csv.item_ids.tolist()))\n",
    "p_pop_all = Counter(tr_csv.target_item.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1646178",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_v_pop_all = tr_csv.item_ids.apply(lambda x: [v_pop_all[y] for y in x])\n",
    "tr_p_pop_all = tr_csv.item_ids.apply(lambda x: [p_pop_all[y] for y in x])\n",
    "\n",
    "val_v_pop_all = val_csv.item_ids.apply(lambda x: [v_pop_all[y] for y in x])\n",
    "val_p_pop_all = val_csv.item_ids.apply(lambda x: [p_pop_all[y] for y in x])\n",
    "\n",
    "te_v_pop_all = te_csv.item_ids.apply(lambda x: [v_pop_all[y] for y in x])\n",
    "te_p_pop_all = te_csv.item_ids.apply(lambda x: [p_pop_all[y] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf39bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pop_3m = Counter(flatten(tr_csv[tr_csv.ym >= \"2021-04\"].item_ids.tolist()))\n",
    "p_pop_3m = Counter(tr_csv[tr_csv.ym >= \"2021-04\"].target_item.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be600bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_v_pop_3m = tr_csv.item_ids.apply(lambda x: [v_pop_3m[y] for y in x])\n",
    "tr_p_pop_3m = tr_csv.item_ids.apply(lambda x: [p_pop_3m[y] for y in x])\n",
    "\n",
    "val_v_pop_3m = val_csv.item_ids.apply(lambda x: [v_pop_3m[y] for y in x])\n",
    "val_p_pop_3m = val_csv.item_ids.apply(lambda x: [p_pop_3m[y] for y in x])\n",
    "\n",
    "te_v_pop_3m = te_csv.item_ids.apply(lambda x: [v_pop_3m[y] for y in x])\n",
    "te_p_pop_3m = te_csv.item_ids.apply(lambda x: [p_pop_3m[y] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b6b78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_s_len = tr_csv.item_ids.apply(len)\n",
    "val_s_len = val_csv.item_ids.apply(len)\n",
    "te_s_len = te_csv.item_ids.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e18d6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tmp = pd.concat([\n",
    "    np.log(1 + tr_s_len),\n",
    "    np.log(1 + tr_dur),\n",
    "    np.log(1 + tr_v_pop_all.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + tr_p_pop_all.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + tr_v_pop_all.apply(lambda x: np.max(x))),\n",
    "    np.log(1 + tr_p_pop_all.apply(lambda x: np.max(x))),\n",
    "    \n",
    "    np.log(1 + tr_v_pop_3m.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + tr_p_pop_3m.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + tr_v_pop_3m.apply(lambda x: np.max(x))),\n",
    "    np.log(1 + tr_p_pop_3m.apply(lambda x: np.max(x))),\n",
    "    \n",
    "], axis=1)\n",
    "\n",
    "val_tmp = pd.concat([\n",
    "   np.log(1 + val_s_len),\n",
    "    np.log(1 + val_dur),\n",
    "    np.log(1 + val_v_pop_all.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + val_p_pop_all.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + val_v_pop_all.apply(lambda x: np.max(x))),\n",
    "    np.log(1 + val_p_pop_all.apply(lambda x: np.max(x))),\n",
    "    \n",
    "    np.log(1 + val_v_pop_3m.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + val_p_pop_3m.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + val_v_pop_3m.apply(lambda x: np.max(x))),\n",
    "    np.log(1 + val_p_pop_3m.apply(lambda x: np.max(x))),\n",
    "], axis=1)\n",
    "\n",
    "te_tmp = pd.concat([\n",
    "   np.log(1 + te_s_len),\n",
    "    np.log(1 + te_dur),\n",
    "    np.log(1 + te_v_pop_all.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + te_p_pop_all.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + te_v_pop_all.apply(lambda x: np.max(x))),\n",
    "    np.log(1 + te_p_pop_all.apply(lambda x: np.max(x))),\n",
    "    \n",
    "    np.log(1 + te_v_pop_3m.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + te_p_pop_3m.apply(lambda x: np.mean(x))),\n",
    "    np.log(1 + te_v_pop_3m.apply(lambda x: np.max(x))),\n",
    "    np.log(1 + te_p_pop_3m.apply(lambda x: np.max(x))),\n",
    "], axis=1)\n",
    "\n",
    "tr_scalar = tr_tmp.to_numpy()\n",
    "val_scalar = val_tmp.to_numpy()\n",
    "te_scalar = te_tmp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfafd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iddf(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d57ffd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_csv['tt'] = tr_csv.date_session_end.apply(lambda x: x[:9]) + ':' + tr_csv.item_ids.apply(lambda x: ':'.join(sorted(x[-5:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d05aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = tr_csv.groupby('tt').target_item.apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "215c57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = {x: y for (x, y) in zip(kw.tt, kw.target_item)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04988df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask_all = tr_csv.item_ids# + tr_csv.tt.apply(lambda x: mask[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8a62985",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for x, y in  zip(input_mask_all, tr_csv.target_item):\n",
    "    r = [k for k in x if k != y]\n",
    "    ret.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54a16fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask_all = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c26a3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_item = sorted(list(set(flatten(tr_csv.item_ids.apply(lambda x: x))) | set(tr_csv.target_item.unique())), key=lambda x: int(x))\n",
    "# lm_item = set(item_to_feats.keys())\n",
    "id2idx = {x:i for i,x in enumerate(lm_item)}\n",
    "item_CV = CountVectorizer(analyzer =iddf, vocabulary=id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fb9a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mask_all = item_CV.transform(input_mask_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07434140",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = tr_mask_all.toarray().sum(-1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cc5e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "BB = item_CV.transform(tr_csv.item_ids).toarray().sum(-1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "406392a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1095497638159416"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(AA - BB).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa5851ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5059, 4932)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_targets = tr_csv.target_item.apply(lambda x: id2idx[x]).tolist()\n",
    "val_targets = val_csv.target_item.apply(lambda x: id2idx.get(x, 29999)).tolist()\n",
    "te_targets = te_csv.target_item.apply(lambda x: id2idx.get(x, 29999)).tolist()\n",
    "(np.array(val_targets) == 29999).sum(), (np.array(te_targets) == 29999).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0bd0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_all = item_CV.transform(tr_csv.item_ids.apply(lambda x: x))\n",
    "last_20 = item_CV.transform(tr_csv.item_ids.apply(lambda x: x[-20:]))\n",
    "last_5 = item_CV.transform(tr_csv.item_ids.apply(lambda x: x[-5:]))\n",
    "last_2 = item_CV.transform(tr_csv.item_ids.apply(lambda x: x[-2:]))\n",
    "last_1 = item_CV.transform(tr_csv.item_ids.apply(lambda x: x[-1:]))\n",
    "\n",
    "val_all = item_CV.transform(val_csv.item_ids.apply(lambda x: x))\n",
    "val_last_20 = item_CV.transform(val_csv.item_ids.apply(lambda x: x[-20:]))\n",
    "val_last5 = item_CV.transform(val_csv.item_ids.apply(lambda x: x[-5:]))\n",
    "val_last2 = item_CV.transform(val_csv.item_ids.apply(lambda x: x[-2:]))\n",
    "val_last1 = item_CV.transform(val_csv.item_ids.apply(lambda x: x[-1:]))\n",
    "\n",
    "te_all = item_CV.transform(te_csv.item_ids.apply(lambda x: x))\n",
    "te_last_20 = item_CV.transform(te_csv.item_ids.apply(lambda x: x[-20:]))\n",
    "te_last5 = item_CV.transform(te_csv.item_ids.apply(lambda x: x[-5:]))\n",
    "te_last2 = item_CV.transform(te_csv.item_ids.apply(lambda x: x[-2:]))\n",
    "te_last1 = item_CV.transform(te_csv.item_ids.apply(lambda x: x[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c1fc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_last_5_feats = tr_csv.item_ids.apply(lambda x: x[-5:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "tr_last_3_feats = tr_csv.item_ids.apply(lambda x: x[-3:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "tr_last_1_feats = tr_csv.item_ids.apply(lambda x: x[-1:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "\n",
    "val_last_5_feats = val_csv.item_ids.apply(lambda x: x[-5:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "val_last_3_feats = val_csv.item_ids.apply(lambda x: x[-3:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "val_last_1_feats = val_csv.item_ids.apply(lambda x: x[-1:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "\n",
    "te_last_5_feats = te_csv.item_ids.apply(lambda x: x[-5:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "te_last_3_feats = te_csv.item_ids.apply(lambda x: x[-3:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "te_last_1_feats = te_csv.item_ids.apply(lambda x: x[-1:]).apply(lambda x: flatten([item_to_feats[y] for y in x]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ecacd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_map = {y: x for (x, y) in enumerate(['2020', '2021'])}\n",
    "month_map = {y: x for (x, y) in enumerate([\"%02d\" % x for x in range(1, 13)])}\n",
    "hour_map = {y: x for (x, y) in enumerate([\"%d\" % x for x in range(0, 24)])}\n",
    "dow_map = {y: x for (x, y) in enumerate(tr_csv.dow.unique())}\n",
    "tr_csv['dow'] = pd.to_datetime(tr_csv.date_session_end).dt.dayofweek.apply(lambda x: str(x))\n",
    "tr_csv['hour'] = pd.to_datetime(tr_csv.date_session_end).dt.hour.apply(lambda x: str(x))\n",
    "\n",
    "val_csv['dow'] = pd.to_datetime(val_csv.date_session_end).dt.dayofweek.apply(lambda x: str(x))\n",
    "val_csv['hour'] = pd.to_datetime(val_csv.date_session_end).dt.hour.apply(lambda x: str(x))\n",
    "\n",
    "te_csv['dow'] = pd.to_datetime(te_csv.date_session_end).dt.dayofweek.apply(lambda x: str(x))\n",
    "te_csv['hour'] = pd.to_datetime(te_csv.date_session_end).dt.hour.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66843ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = flatten([item_to_feats[x] for x in lm_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1c894a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = set(all_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d598f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = set(flatten(item_to_feats.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8704240",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2fidx = item_to_feats.keys()\n",
    "feat_CV = CountVectorizer(analyzer=iddf, \n",
    "                          vocabulary=all_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28a763bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_feats = normalize(feat_CV.transform([item_to_feats[x] for x in lm_item]), norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ce31cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_l5_feats = normalize(feat_CV.transform(tr_last_5_feats), norm='l1').toarray()\n",
    "tr_l3_feats = normalize(feat_CV.transform(tr_last_3_feats), norm='l1').toarray()\n",
    "tr_l1_feats = normalize(feat_CV.transform(tr_last_1_feats), norm='l1').toarray()\n",
    "\n",
    "val_l5_feats = normalize(feat_CV.transform(val_last_5_feats), norm='l1').toarray()\n",
    "val_l3_feats = normalize(feat_CV.transform(val_last_3_feats), norm='l1').toarray()\n",
    "val_l1_feats = normalize(feat_CV.transform(val_last_1_feats), norm='l1').toarray()\n",
    "\n",
    "te_l5_feats = normalize(feat_CV.transform(te_last_5_feats), norm='l1').toarray()\n",
    "te_l3_feats = normalize(feat_CV.transform(te_last_3_feats), norm='l1').toarray()\n",
    "te_l1_feats = normalize(feat_CV.transform(te_last_1_feats), norm='l1').toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecdd6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 16\n",
    "tr_cats = {\n",
    "#     \"year\": (tr_csv['year'].apply(lambda x: year_map[x]).tolist(), (2, EMBED_DIM)),\n",
    "#     \"month\": (tr_csv['month'].apply(lambda x: month_map[x]).tolist(), (12, EMBED_DIM)),\n",
    "    \"dow\": (tr_csv['dow'].apply(lambda x: dow_map[x]).tolist(), (7, EMBED_DIM)),\n",
    "    \"hour\": (tr_csv['hour'].apply(lambda x: hour_map[x]).tolist(), (25, EMBED_DIM)),\n",
    "}\n",
    "\n",
    "val_cats = {\n",
    "#     \"year\": (val_csv['year'].apply(lambda x: year_map[x]).tolist(), (2, EMBED_DIM)),\n",
    "#     \"month\": (val_csv['month'].apply(lambda x: month_map[x]).tolist(), (12, EMBED_DIM)),\n",
    "    \"dow\": (val_csv['dow'].apply(lambda x: dow_map[x]).tolist(), (7, EMBED_DIM)),\n",
    "    \"hour\": (val_csv['hour'].apply(lambda x: hour_map[x]).tolist(), (25, EMBED_DIM)),    \n",
    "}\n",
    "\n",
    "te_cats = {\n",
    "#     \"year\": (te_csv['year'].apply(lambda x: year_map[x]).tolist(), (2, EMBED_DIM)),\n",
    "#     \"month\": (te_csv['month'].apply(lambda x: month_map[x]).tolist(), (12, EMBED_DIM)),\n",
    "    \"dow\": (te_csv['dow'].apply(lambda x: dow_map[x]).tolist(), (7, EMBED_DIM)),\n",
    "    \"hour\": (te_csv['hour'].apply(lambda x: hour_map[x]).tolist(), (25, EMBED_DIM)),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0aaa7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mats = {\n",
    "    \"item_bow\": item_all, \n",
    "    \"item_last_20\": last_20,\n",
    "    \"item_last_5\": last_5,\n",
    "    \"item_last_2\": last_2,\n",
    "    \"item_last_1\": last_1,\n",
    "#     'item_all_feats': tr_feats,    \n",
    "    'item_last_5_feats': tr_l5_feats,\n",
    "    \"item_last_3_feats\" : tr_l3_feats,\n",
    "    \"item_last_1_feats\" : tr_l1_feats,\n",
    "#     \"last_hits\": tr_vm_hit,\n",
    "}\n",
    "\n",
    "val_mats  = {\n",
    "    \"item_bow\": val_all, \n",
    "    \"item_last_20\": val_last_20,\n",
    "    \"item_last_5\": val_last5,\n",
    "    \"item_last_2\": val_last2,\n",
    "    \"item_last_1\": val_last1,\n",
    "#     'item_all_feats': val_feats,    \n",
    "    'item_last_5_feats': val_l5_feats,\n",
    "    \"item_last_3_feats\" : val_l3_feats,\n",
    "    \"item_last_1_feats\" : val_l1_feats,\n",
    "#     \"item_last_5_feats\": val_last_5_feats,\n",
    "#     \"last_hits\": val_vm_hit,\n",
    "}\n",
    "\n",
    "te_mats  = {\n",
    "    \"item_bow\": te_all, \n",
    "    \"item_last_20\": te_last_20,\n",
    "    \"item_last_5\": te_last5,\n",
    "    \"item_last_2\": te_last2,\n",
    "    \"item_last_1\": te_last1,\n",
    "#     'item_all_feats': te_feats,    \n",
    "    'item_last_5_feats': te_l5_feats,\n",
    "    \"item_last_3_feats\" : te_l3_feats,\n",
    "    \"item_last_1_feats\" : te_l1_feats,\n",
    "#     \"item_last_5_feats\": te_last_5_feats,\n",
    "#     \"last_hits\": te_vm_hit,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d99f3259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mlps' from '/data/project/rw/recsys-challenge-2022-2105/mlp/mlps.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlps\n",
    "importlib.reload(mlps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ac8d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask_all = item_CV.transform(val_csv.item_ids)\n",
    "te_mask_all = item_CV.transform(te_csv.item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4d04b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = mlps.dictDataset(tr_mask_all, tr_mats, tr_cats, tr_scalar, tr_targets)\n",
    "val_ds = mlps.dictDataset(val_mask_all, val_mats, val_cats, val_scalar, val_targets)\n",
    "te_ds = mlps.dictDataset(te_mask_all, te_mats, te_cats, te_scalar, te_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84bb5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./procseed_data_with_aug\n",
    "!mkdir ./procseed_data_with_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c87291b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname ='procseed_data_with_aug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33e47cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procseed_data_with_aug/lm_feats']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lm_feats, '%s/lm_feats' % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a530a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['procseed_data_with_aug/cv']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(val_ds, \"%s/val_ds\" % fname)\n",
    "joblib.dump(tr_ds, '%s/tr_ds' % fname)\n",
    "joblib.dump(te_ds, '%s/te_ds' % fname)\n",
    "joblib.dump(te_csv, \"%s/te_csv\" % fname)\n",
    "joblib.dump(val_csv, \"%s/val_csv\" % fname)\n",
    "joblib.dump(tr_csv, '%s/tr_csv' % fname)\n",
    "joblib.dump(id2idx, '%s/id2idx' % fname )\n",
    "joblib.dump((item_CV, feat_CV), \"%s/cv\" % fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
