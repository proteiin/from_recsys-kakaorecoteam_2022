{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad72042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as ssp\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from os.path import join as pjoin\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import importlib \n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "import pytorch_lightning as pl\n",
    "from os.path import join as pjoin\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3469dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"procseed_data_with_aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a09587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_feats = joblib.load('%s/lm_feats' % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc07ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = joblib.load('%s/tr_ds' % fname)\n",
    "val_ds = joblib.load(\"%s/val_ds\" % fname) \n",
    "id2idx = joblib.load('%s/id2idx' % fname)\n",
    "idx2id = {y:x for (x,y) in id2idx.items()}\n",
    "n_items = len(id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb63a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv = joblib.load(\"%s/val_csv\" % fname)\n",
    "tr_csv = joblib.load('%s/tr_csv' % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cc6a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1.5 * 1e-4\n",
    "import mlps\n",
    "importlib.reload(mlps)\n",
    "\n",
    "def get_model(dim=256):\n",
    "    return mlps.MLP2(lm_feats.toarray(), tr_ds.matrices, \n",
    "                    tr_ds.categoricals,  \n",
    "                    tr_ds.tr_scalar,\n",
    "                    n_items=n_items, \n",
    "                    dim=np.random.choice([256]), \n",
    "                    layer_dim=np.random.choice([3000]),\n",
    "                    dropout=np.random.choice([0.3, 0.35]),\n",
    "                    use_cat=False)\n",
    "\n",
    "mlp_models = [get_model() for x in range(10)]\n",
    "\n",
    "def get_opts(model):\n",
    "    wd = np.random.choice([1e-3])\n",
    "    return torch.optim.Adam(model.parameters(),  lr=lr, weight_decay=wd)\n",
    "    \n",
    "opts = [get_opts(model) for model in mlp_models]\n",
    "\n",
    "for m in mlp_models:\n",
    "    m.cuda()\n",
    "    m.train()\n",
    "\n",
    "lf = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b61d2f",
   "metadata": {},
   "source": [
    "이렇게 3개고 last view만 aug해줬을 때 성능이 0.1928이 나옴?\n",
    "0.3, 0.35, 0.3 \n",
    "5e-3, 5e-3 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b94b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = DataLoader(tr_ds,\n",
    "                   batch_size=256, shuffle=False,\n",
    "                   num_workers=8, prefetch_factor=2,\n",
    "#                    persistent_workers=True,\n",
    "                   pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9211e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_ds, use_filter=True, skip_val_only=False):\n",
    "    hr = []\n",
    "    model = model.eval()\n",
    "    s = 0\n",
    "    tot_mrr = []\n",
    "    ii = 0\n",
    "    for input in DataLoader(val_ds, batch_size=250, shuffle=False):\n",
    "        (target_idx, _), (ret_mat, ret_cat, ret_scalar) = input\n",
    "        for k in ret_mat:\n",
    "            ret_mat[k] = ret_mat[k].cuda()\n",
    "        for k in ret_cat:\n",
    "            ret_cat[k] = ret_cat[k].cuda()\n",
    "#         ret_cat = {}\n",
    "        ret_scalar = ret_scalar.cuda()\n",
    "        ret = model.forward(ret_mat, ret_cat, ret_scalar,)\n",
    "        ret[ret_mat['item_bow'].bool()] = -1000000.0\n",
    "#         ret[:, ~z] = -10000000.0\n",
    "        top_rec = (-ret).argsort(-1)[:, :100].cpu()\n",
    "\n",
    "        \n",
    "        if skip_val_only:\n",
    "            top_rec = top_rec[target_idx != 29999]\n",
    "            target_idx = target_idx[target_idx != 29999]\n",
    "            \n",
    "        mrr = (top_rec == target_idx.unsqueeze(1)).float().numpy() \n",
    "        mrr = (mrr / np.expand_dims(np.arange(1, 1 + 100), 0))\n",
    "        mrr = mrr.sum(-1)\n",
    "        tot_mrr.extend(mrr.tolist())\n",
    "#         break\n",
    "    model = model.train()\n",
    "    return np.mean(tot_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    ret = []\n",
    "    for k in x:\n",
    "        ret.extend(k)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbeaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_models(models, val_ds, use_filter=True, skip_val_only=False, r=None):\n",
    "    hr = []\n",
    "    for model in models:\n",
    "        model = model.eval()\n",
    "    s = 0\n",
    "    tot_mrr = []\n",
    "    ii = 0\n",
    "    for input in DataLoader(val_ds, batch_size=250, shuffle=False):\n",
    "        (target_idx, _), (ret_mat, ret_cat, ret_scalar) = input\n",
    "        for k in ret_mat:\n",
    "            ret_mat[k] = ret_mat[k].cuda()\n",
    "        for k in ret_cat:\n",
    "            ret_cat[k] = ret_cat[k].cuda()\n",
    "        ret_scalar = ret_scalar.cuda()\n",
    "        rret = []\n",
    "        for model in models:\n",
    "            ret = model.forward(ret_mat, ret_cat, ret_scalar,)\n",
    "            rret.append(ret)\n",
    "        ret = torch.stack(rret)\n",
    "        ret = torch.mean(ret, 0)\n",
    "        ret[ret_mat['item_bow'].bool()] = -10000.0\n",
    "        if r is not None:\n",
    "            print(r.shape)\n",
    "            ret[:, ~r] = -100000.0\n",
    "        top_rec = (-ret).argsort(-1)[:, :100].detach().cpu()\n",
    "\n",
    "#         if skip_val_only:\n",
    "#         top_rec = top_rec[target_idx != 29999]\n",
    "#         target_idx = target_idx[target_idx != 29999]\n",
    "\n",
    "        mrr = (top_rec == target_idx.unsqueeze(1)).float().numpy()\n",
    "        hitst = mrr[:, :5].sum(-1)\n",
    "        mrr = (mrr / np.expand_dims(np.arange(1, 1 + 100), 0)).sum(-1)\n",
    "        tot_mrr.extend(mrr.tolist())\n",
    "        hr.extend(hitst)\n",
    "    for model in models:\n",
    "        model = model.train()\n",
    "    return np.mean(tot_mrr), np.mean(hr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_models(mlp_models, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634d6e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:23<00:00,  4.49it/s, loss:=6.7593]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.52it/s, loss:=6.4406]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.52it/s, loss:=6.2893]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.53it/s, loss:=6.1828]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:23<00:00,  4.50it/s, loss:=6.0834]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:20<00:00,  4.53it/s, loss:=6.0039]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:20<00:00,  4.54it/s, loss:=5.9428]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:22<00:00,  4.50it/s, loss:=5.8863]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:23<00:00,  4.49it/s, loss:=5.8418]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.53it/s, loss:=5.7994]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.52it/s, loss:=5.7621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 11] VAL MRR: 0.18113330794589702 HR 0.25333267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:22<00:00,  4.50it/s, loss:=5.7276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 12] VAL MRR: 0.18345126213858043 HR 0.2569594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.53it/s, loss:=5.7004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 13] VAL MRR: 0.1848440537273383 HR 0.2582827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.52it/s, loss:=5.6662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 14] VAL MRR: 0.1858921300705072 HR 0.25862575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:22<00:00,  4.51it/s, loss:=5.6443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 15] VAL MRR: 0.18743598634104652 HR 0.26065966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:22<00:00,  4.51it/s, loss:=5.6134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 16] VAL MRR: 0.18848375335278925 HR 0.26163986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:22<00:00,  4.50it/s, loss:=5.5894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 17] VAL MRR: 0.1891440301597899 HR 0.26257107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:20<00:00,  4.53it/s, loss:=5.5634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 18] VAL MRR: 0.19010967347464505 HR 0.2637473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:21<00:00,  4.52it/s, loss:=5.5410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 19] VAL MRR: 0.19051317620114966 HR 0.26541364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [05:23<00:00,  3.65it/s, loss:=5.5171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 20] VAL MRR: 0.19115881084986036 HR 0.26541364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [07:25<00:00,  2.65it/s, loss:=5.4975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 21] VAL MRR: 0.1910712495037268 HR 0.26609978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [07:30<00:00,  2.63it/s, loss:=5.4804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 22] VAL MRR: 0.19186360448108652 HR 0.26624683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [07:40<00:00,  2.57it/s, loss:=5.4503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 23] VAL MRR: 0.19182314951462576 HR 0.26685944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [06:00<00:00,  3.28it/s, loss:=5.4321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 24] VAL MRR: 0.19198757499628133 HR 0.26644287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:26<00:00,  4.44it/s, loss:=5.4142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 25] VAL MRR: 0.19202118267939486 HR 0.2671535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:28<00:00,  4.40it/s, loss:=5.3930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 26] VAL MRR: 0.19203559642530268 HR 0.26732504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:39<00:00,  4.24it/s, loss:=5.3697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 27] VAL MRR: 0.1919688740246477 HR 0.26737404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [07:28<00:00,  2.64it/s, loss:=5.3557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 28] VAL MRR: 0.19207685421335885 HR 0.26742306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [05:08<00:00,  3.83it/s, loss:=5.3324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 29] VAL MRR: 0.1920064363264407 HR 0.26705548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1183/1183 [04:38<00:00,  4.25it/s, loss:=5.3147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 30] VAL MRR: 0.19188591253521042 HR 0.26730052\n"
     ]
    }
   ],
   "source": [
    "loss_ = np.log(n_items)\n",
    "max_mrr = -1\n",
    "for epoch in range(30):\n",
    "    it = 0\n",
    "    iidx = 0\n",
    "    pbar = tqdm(tr_dl)\n",
    "    for x in pbar:\n",
    "        (target_idx, mask), (mats, cats, scalars) = x\n",
    "        target_idx = target_idx.cuda()\n",
    "        mask = mask.cuda().squeeze(1)\n",
    "        for k in mats:\n",
    "            mats[k] = mats[k].cuda()\n",
    "        for k in cats:\n",
    "            cats[k] = cats[k].cuda()\n",
    "#         cats = {}\n",
    "        scalars = scalars.cuda()\n",
    "        for model, optimizer in zip(mlp_models, opts):\n",
    "            model.zero_grad()\n",
    "            pred = model(mats, cats, scalars)\n",
    "            pred[mask.bool()] = -10000.0\n",
    "#             pos = pred[torch.arange(pred.shape[0]).cuda(), target_idx]\n",
    "#             pred[torch.arange(pred.shape[0]).cuda(), target_idx] = -1000.0\n",
    "#             T = torch.clamp(-pos.unsqueeze(1) + pred + 1.5, min=0)\n",
    "#             T = T.sum(-1) / (1e-8 + (T > 0).sum(-1).float())\n",
    "#             loss_2 = T.mean()\n",
    "#     #         loss = ce_loss + 0.01 * loss_2.mean()\n",
    "\n",
    "#             loss = loss_2\n",
    "            loss = lf(pred, target_idx)\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "        loss_ = 0.99 * loss_  + 0.01 * loss.detach().cpu().numpy()\n",
    "        pbar.set_postfix({'loss:': \"%0.4f\" % loss_})\n",
    "\n",
    "    model = mlp_models[0]\n",
    "    if epoch < 10:\n",
    "        continue\n",
    "    mrr, hr = validate_models(mlp_models, val_ds)\n",
    "    if mrr >= max_mrr:\n",
    "        max_mrr = mrr\n",
    "        torch.save(mlp_models, \"val_no_shuffle_mlp\")\n",
    "    print(\"[ITER %d] VAL MRR:\" % (1 + epoch), mrr, \"HR\", hr)\n",
    "    model = model.train()\n",
    "    model.cuda()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
